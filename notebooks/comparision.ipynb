{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13dceb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiten/rishit/api_new/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from docx import Document\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "global collection,status_msg\n",
    "status_msg = {}\n",
    "# --------------------------\n",
    "# 1. Load and Chunk Document\n",
    "# --------------------------\n",
    "\n",
    "# defining path constants\n",
    "output_folder = 'expert/extracted_controls'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "def clean_text(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "\n",
    "    control_blocks = []\n",
    "    current_block = []\n",
    "\n",
    "    # Regex for ID (numbers only OR A.12.3)\n",
    "    control_id_pattern = re.compile(r'\\b(?:[A-Z]+(?:\\.[A-Z]+)*-?)?\\d+(?:\\.\\d+)*\\b')\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "        if not stripped:\n",
    "            continue\n",
    "\n",
    "        # Detect start of a new control\n",
    "        if control_id_pattern.match(stripped):\n",
    "            if current_block:\n",
    "                control_blocks.append(\"\\n\".join(current_block))\n",
    "            current_block = [stripped]\n",
    "        else:\n",
    "            if current_block:\n",
    "                current_block.append(stripped)\n",
    "\n",
    "    if current_block:\n",
    "        control_blocks.append(\"\\n\".join(current_block))\n",
    "\n",
    "    final_blocks = []\n",
    "\n",
    "    for block in control_blocks:\n",
    "        block_lines = block.strip().split(\"\\n\")\n",
    "\n",
    "        # -------------------------\n",
    "        # 1. CHECK ID\n",
    "        # -------------------------\n",
    "        first_line = block_lines[0]\n",
    "        if not control_id_pattern.match(first_line):\n",
    "            continue\n",
    "\n",
    "        # -------------------------\n",
    "        # 2. CHECK NAME (Title)\n",
    "        # It can be on SAME line OR NEXT line\n",
    "        # -------------------------\n",
    "\n",
    "        name_found = False\n",
    "\n",
    "        # (A) Try same line (after removing ID)\n",
    "        first_line_without_id = control_id_pattern.sub(\"\", first_line).strip()\n",
    "        if re.search(r'[A-Za-z]', first_line_without_id):\n",
    "            name_found = True\n",
    "\n",
    "        # (B) Try next line if no name found yet\n",
    "        if not name_found and len(block_lines) > 1:\n",
    "            second_line = block_lines[1].strip()\n",
    "            # Next line should contain alphabetic words (name/title)\n",
    "            if re.search(r'[A-Za-z]', second_line) and len(second_line.split()) <= 10:\n",
    "                # Names are usually short (<=10 words)\n",
    "                name_found = True\n",
    "\n",
    "        if not name_found:\n",
    "            continue    # ❌ No title → discard entire block\n",
    "\n",
    "        # -------------------------\n",
    "        # 3. CHECK DESCRIPTION\n",
    "        # Description must contain ≥5 words (after removing ID & name)\n",
    "        # -------------------------\n",
    "        # Description starts from either 2nd or 3rd line\n",
    "        desc_start_index = 1 if first_line_without_id else 2\n",
    "\n",
    "        description_lines = block_lines[desc_start_index:]\n",
    "        description_text = \" \".join(description_lines).strip()\n",
    "\n",
    "        # Remove pure titles from description\n",
    "        # Description must have meaningful text\n",
    "        if len(description_text.split()) <2:\n",
    "            continue  # ❌ Not enough meaningful info\n",
    "\n",
    "        # All 3 components exist → keep block\n",
    "        final_blocks.append(block)\n",
    "\n",
    "    return \"\\n\\n\".join(final_blocks)\n",
    "\n",
    "\n",
    "def normalize_docx_spacing(text):\n",
    "    # Remove spacing between single characters\n",
    "    # \"t o   P I I\" → \"to PII\"\n",
    "    text = re.sub(r\"(?<=\\w)\\s+(?=\\w)\", \" \", text)\n",
    "\n",
    "    # Remove double or triple spaces\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "#The following function returns output in list form with cleaning of text\n",
    "\n",
    "#The following function returns output in String form\n",
    "def load_docx(path):\n",
    "    doc = Document(path)\n",
    "    lines = []\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()\n",
    "        if text:\n",
    "            lines.append(text)\n",
    "\n",
    "    # Return as a single string (joined by newline)\n",
    "\n",
    "    return normalize_docx_spacing(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "def load_pdf_text(file_path):\n",
    "    \"\"\"\n",
    "    Loads and extracts text from a PDF file.\n",
    "    Returns the extracted text in the form of a list.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "            text=clean_text(text)\n",
    "\n",
    "    return text.split(\"\\n\")\n",
    "\n",
    "def load_txt(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read().split(\"\\n\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def load_excel(file_path):\n",
    "    xls = pd.ExcelFile(file_path)\n",
    "    text = \"\"\n",
    "\n",
    "    for sheet in xls.sheet_names:\n",
    "        df = pd.read_excel(xls, sheet_name=sheet)\n",
    "        text += df.to_string(index=False) + \"\\n\\n\"\n",
    "\n",
    "    return text.split(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "def load_document(file_path):\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    print(ext)\n",
    "\n",
    "    if ext == \".docx\":\n",
    "        return load_docx(file_path)\n",
    "    elif ext == \".pdf\":\n",
    "        return load_pdf_text(file_path)\n",
    "    elif ext == \".txt\":\n",
    "        return load_txt(file_path)\n",
    "    elif ext in [\".xls\", \".xlsx\"]:\n",
    "        return load_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "\n",
    "#Extracting controls from the document of Client\n",
    "\n",
    "\n",
    "#The following function removes bullets, dots and numbering\n",
    "def clean_leading_bullets(text):\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    # remove typical bullet characters\n",
    "    text = re.sub(r\"^[\\s•·▪○●►▶↳\\-\\*]+\", \"\", text)\n",
    "\n",
    "    # remove stray dots like \". \" or \" . \"\n",
    "    text = re.sub(r\"^\\s*\\.\\s*\", \"\", text)\n",
    "    \"\"\"\n",
    "    Removes leading numbering patterns like:\n",
    "    '8. Text', '8) Text', '(8) Text', '8 - Text', '8: Text'\n",
    "    \"\"\"\n",
    "    return re.sub(r\"^\\s*\\(?\\d+\\)?\\s*[\\.\\:\\-\\)]\\s*\", \"\", text).strip()\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "semantic_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def semantic_similarity(text1, text2):\n",
    "    emb1 = semantic_model.encode(text1, convert_to_tensor=True)\n",
    "    emb2 = semantic_model.encode(text2, convert_to_tensor=True)\n",
    "    score = util.cos_sim(emb1, emb2).item()\n",
    "    return round(float(score), 4)\n",
    "\n",
    "def compare_controls(framework_df, client_list):\n",
    "    results = []\n",
    "\n",
    "    for client in client_list:\n",
    "        c_name = client[\"Client_Control_Name\"]\n",
    "        c_desc = client[\"Client_Control_Description\"]\n",
    "\n",
    "        best_match = None\n",
    "        best_score = -1\n",
    "\n",
    "        # ---------- Search best framework match ----------\n",
    "        for _, row in framework_df.iterrows():\n",
    "\n",
    "            f_id   = row.get(\"Control_id\", \"\")\n",
    "            f_name = row.get(\"Control_name\", \"\")\n",
    "            f_desc = row.get(\"Control_description\", \"\")\n",
    "\n",
    "            deployment_pts =row.get(\"Deployment_points\", \"\")\n",
    "\n",
    "            # FULL comparison text\n",
    "            framework_text = f\"{f_name} {f_desc} {deployment_pts}\"\n",
    "            client_text    = f\"{c_name} {c_desc}\"\n",
    "\n",
    "            score = semantic_similarity(client_text, framework_text)\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = row\n",
    "\n",
    "        # ---------- Add only the BEST match result ----------\n",
    "        results.append({\n",
    "            \"Client_Control_Name\": c_name,\n",
    "            \"Client_Control_Description\": c_desc,\n",
    "            \"Framework_Control_Id\": best_match.get(\"Control_id\", \"\"),\n",
    "            \"Framework_Control_Name\": best_match.get(\"Control_name\", \"\"),\n",
    "            \"Framework_Control_Description\": best_match.get(\"Control_description\", \"\"),\n",
    "            \"Deployment_Points\": best_match.get(\"Deployment_points\", []),\n",
    "            \"Comparison_Score\": best_score\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "#--------------------------------\n",
    "# Creating chunks of the text\n",
    "#--------------------------------\n",
    "def chunk_text(text_list, chunk_size=1000):\n",
    "    chunks = []\n",
    "    current = \"\"\n",
    "\n",
    "    for line in text_list:\n",
    "        if len(current) + len(line) <= chunk_size:\n",
    "            current += \" \" + line\n",
    "        else:\n",
    "            chunks.append(current.strip())\n",
    "            current = line\n",
    "\n",
    "    if current:\n",
    "        chunks.append(current.strip())\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 3. Insert chunks into vector DB\n",
    "# --------------------------\n",
    "def insert_into_chroma(collection, chunks):\n",
    "    ids = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        ids.append(str(i))\n",
    "    collection.add(\n",
    "        documents=chunks,\n",
    "        ids=ids\n",
    "    )\n",
    "\n",
    "# --------------------------\n",
    "# NEW: Retrieve similar chunks (RAG Retrieval)\n",
    "# --------------------------\n",
    "def retrieve_similar_chunks(collection, query, top_k=70):\n",
    "    \"\"\"\n",
    "    Return clean list of chunk strings.\n",
    "    \"\"\"\n",
    "    result = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=top_k\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        docs = result[\"documents\"][0]\n",
    "        return [d for d in docs if d.strip()]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# 4. RAG QUERY: Ask LLM to Extract Controls\n",
    "# --------------------------\n",
    "client = OpenAI(api_key=os.environ['openai_key'])\n",
    "\n",
    "import json\n",
    "# --------------------------\n",
    "# 4. EXTRACT CONTROL: Ask LLM to Extract Controls  (modified to use a list of strings)\n",
    "# --------------------------\n",
    "REGEX = r\"\\b(?:[A-Z]+(?:\\.[A-Z]+)*[-.]?)?\\d+(?:\\.\\d+)*\\b\"\n",
    "def extract_controls_full(chunks,uuid_of_file):\n",
    "    global status_msg\n",
    "\n",
    "    '''\n",
    "    # 1. Retrieve top relevant chunks\n",
    "    rag_chunks = retrieve_similar_chunks(query, top_k=70)\n",
    "\n",
    "    print(\"Retrieved chunks = \", len(rag_chunks))\n",
    "    for i, c in enumerate(rag_chunks):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{c[:400]}\\n\")\n",
    "\n",
    "\n",
    "    # If RAG fails, fallback to all chunks\n",
    "    if not rag_chunks:\n",
    "        rag_chunks = chunks\n",
    "    #The following variable is used in the prompt (for extraction of the controls)\n",
    "    #This way relevant chunks are used for this purpose\n",
    "\n",
    "    #rag_chunks = chunks\n",
    "    combined_context = \"\\n\\n---\\n\\n\".join(rag_chunks)\n",
    "    '''\n",
    "    prompt = f\"\"\"\n",
    "You are a strict JSON generator.\n",
    "Extract ALL compliance controls from the following text.\n",
    "Do NOT skip ANY control.\n",
    "Do NOT give anything extra.\n",
    "Strictly search in the document.\n",
    "\n",
    "STRICTLY extract all control IDs using the regex ONLY.\n",
    "\n",
    "Do NOT invent or skip any ID.\n",
    "\n",
    "STRICTLY extract all control IDs using this regex:\n",
    "{REGEX!r}\n",
    "\n",
    "Treat ALL numeric headings (0.1,0.2,0.3,0.4,1.1,1.2,2.3,1.1.2,A.1.2,A.2 etc.) as controls.\n",
    "Do NOT treat them as TOC headings.\n",
    "\n",
    "EXTRACT ONLY if all three are present in this sequence- ID, NAME and DESCRIPTION otherwise return null.\n",
    "\n",
    "DESCRIPTION CAN BE OF 5 TO 1500 characters.\n",
    "\n",
    "Consider all the controls given till the end.\n",
    "\n",
    "Use JSON list ONLY:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"Control_id\": \"\",\n",
    "    \"Control_name\": \"\",\n",
    "    \"Control_type\":\"\",\n",
    "    \"Control_description\": \"\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "TEXT:\n",
    "{chunks}\n",
    "\n",
    "Return ONLY JSON. No markdown. No text outside JSON.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"extracting controls\")\n",
    "    status_msg[uuid_of_file] = \"extracting controls from document.\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    status_msg[uuid_of_file] = \"extracting deployment points.\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an anlyser/interpreter.\n",
    "From each of the given compliance controls in the given JSON, analyse and retrieve the deployment points.\n",
    "Do NOT skip ANY control.\n",
    "\n",
    "\n",
    "INTERPRET THE TEXT IN THE DESCRIPTION AND GENERATE 5 to 6 POINTS FOR THE DEPLOYMENT (for each control seperatrly).\n",
    "STORE THE DEPLOYMENT related points under Deployment_points heading.\n",
    "Deployment points must describe:\n",
    "- how this control is implemented,\n",
    "- what actions/steps are required,\n",
    "- how to operationalize the control.\n",
    "- any other important point of deployment.\n",
    "Every point should be numbered.\n",
    "All the points should be stored in the form of a single string.\n",
    "\n",
    "Use the following JSON for the above operation:\n",
    "{response}\n",
    "\n",
    "After the above retrieval operation, add one more heading in the JSON - Deployment_points and store the deployment points in it.\n",
    "Use JSON list ONLY:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"Control_id\": \"\",\n",
    "    \"Control_name\": \"\",\n",
    "    \"Control_type\":\"\",\n",
    "    \"Control_description\": \"\",\n",
    "    \"Deployment_points\": \"\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "TEXT:\n",
    "{chunks}\n",
    "\n",
    "Return ONLY JSON. No markdown. No text outside JSON.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"extracting deployment points.\")\n",
    "    status_msg[uuid_of_file] = \"extracting deployment points\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        print(\"⚠ JSON error\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def remove_duplicate_controls(controls):\n",
    "    \"\"\"\n",
    "    Removes duplicate controls based on Control_id.\n",
    "    Keeps only the FIRST occurrence and discards others.\n",
    "    \"\"\"\n",
    "    unique = {}\n",
    "    cleaned_list = []\n",
    "\n",
    "    for ctrl in controls:\n",
    "        cid = ctrl.get(\"Control_id\", \"\").strip()\n",
    "\n",
    "        # Skip invalid entries\n",
    "        if cid == \"\":\n",
    "            continue\n",
    "\n",
    "        # Keep only the first time a Control_id appears\n",
    "        if cid not in unique:\n",
    "            unique[cid] = True\n",
    "            cleaned_list.append(ctrl)\n",
    "\n",
    "    return cleaned_list\n",
    "# --------------------------\n",
    "# 5. RUN PIPELINE\n",
    "# --------------------------\n",
    "\n",
    "# --------------------------\n",
    "#Setup ChromaDB (Vector DB)\n",
    "# --------------------------\n",
    "\n",
    "\n",
    "def extract_controls(file_path,uuid_of_file):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"chroma_db/\")\n",
    "\n",
    "    # Always reset the collection so old chunks do not pollute results\n",
    "    try:\n",
    "        chroma_client.delete_collection(\"controls_collection\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=\"controls_collection\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "\n",
    "    # Step 1: Load document\n",
    "    text_content_list = load_document(file_path)\n",
    "\n",
    "\n",
    "    # Step 2: Chunk text\n",
    "    chunks = chunk_text(text_content_list)\n",
    "\n",
    "    # Step 3: Insert into vector DB\n",
    "    insert_into_chroma(collection,chunks)\n",
    "    #import time\n",
    "    #time.sleep(15)\n",
    "    # Step 4: Run extraction\n",
    "    #controls = extract_controls_full(chunks)\n",
    "    #query = \"List all compliance control statements, IDs, Names, Types and Descriptions.\"\n",
    "    out_path = os.path.join(output_folder,uuid_of_file+\".json\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    output_file = out_path\n",
    "\n",
    "    # --- Check if JSON already exists ---\n",
    "    if os.path.exists(output_file):\n",
    "        print(\"JSON file already exists. Loading existing controls...\")\n",
    "\n",
    "        with open(output_file, \"r\") as f:\n",
    "            json_text = f.read()\n",
    "\n",
    "        controls = json.loads(json_text)\n",
    "\n",
    "    else:\n",
    "        print(\"Extracting controls...\")\n",
    "\n",
    "        controls = extract_controls_full(chunks,uuid_of_file)   \n",
    "\n",
    "        # Convert to JSON text\n",
    "        json_text = json.dumps(controls, indent=2)\n",
    "\n",
    "        # Save JSON to file\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(json_text)\n",
    "\n",
    "        print(\"JSON saved to:\", output_file)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "def extract_controls_user(file_path,uuid_of_file):\n",
    "    chroma_client = chromadb.PersistentClient(path=\"chroma_db/\")\n",
    "\n",
    "    # Always reset the collection so old chunks do not pollute results\n",
    "    try:\n",
    "        chroma_client.delete_collection(\"controls_collection\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    collection = chroma_client.create_collection(\n",
    "        name=\"controls_collection\",\n",
    "        metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "\n",
    "    # Step 1: Load document\n",
    "    text_content_list = load_document(file_path)\n",
    "\n",
    "\n",
    "    # Step 2: Chunk text\n",
    "    chunks = chunk_text(text_content_list)\n",
    "\n",
    "    # Step 3: Insert into vector DB\n",
    "    insert_into_chroma(collection,chunks)\n",
    "    #import time\n",
    "    #time.sleep(15)\n",
    "    # Step 4: Run extraction\n",
    "    #controls = extract_controls_full(chunks)\n",
    "    #query = \"List all compliance control statements, IDs, Names, Types and Descriptions.\"\n",
    "    out_path = os.path.join(output_folder,uuid_of_file+\".json\")\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    output_file = out_path\n",
    "\n",
    "    # --- Check if JSON already exists ---\n",
    "    if os.path.exists(output_file):\n",
    "        print(\"JSON file already exists. Loading existing controls...\")\n",
    "\n",
    "        with open(output_file, \"r\") as f:\n",
    "            json_text = f.read()\n",
    "\n",
    "        controls = json.loads(json_text)\n",
    "\n",
    "    else:\n",
    "        print(\"Extracting controls...\")\n",
    "\n",
    "        controls = extract_controls_only(chunks,uuid_of_file)   \n",
    "\n",
    "        # Convert to JSON text\n",
    "        json_text = json.dumps(controls, indent=2)\n",
    "\n",
    "        # Save JSON to file\n",
    "        with open(output_file, \"w\") as f:\n",
    "            f.write(json_text)\n",
    "\n",
    "        print(\"JSON saved to:\", output_file)\n",
    "\n",
    "    print(\"done\")\n",
    "\n",
    "\n",
    "def extract_controls_only(chunks,uuid_of_file):\n",
    "    global status_msg\n",
    "\n",
    "    '''\n",
    "    # 1. Retrieve top relevant chunks\n",
    "    rag_chunks = retrieve_similar_chunks(query, top_k=70)\n",
    "\n",
    "    print(\"Retrieved chunks = \", len(rag_chunks))\n",
    "    for i, c in enumerate(rag_chunks):\n",
    "        print(f\"\\n--- Chunk {i+1} ---\\n{c[:400]}\\n\")\n",
    "\n",
    "\n",
    "    # If RAG fails, fallback to all chunks\n",
    "    if not rag_chunks:\n",
    "        rag_chunks = chunks\n",
    "    #The following variable is used in the prompt (for extraction of the controls)\n",
    "    #This way relevant chunks are used for this purpose\n",
    "\n",
    "    #rag_chunks = chunks\n",
    "    combined_context = \"\\n\\n---\\n\\n\".join(rag_chunks)\n",
    "    '''\n",
    "    prompt = f\"\"\"\n",
    "You are a strict JSON generator.\n",
    "Extract ALL compliance controls from the following text.\n",
    "Do NOT skip ANY control.\n",
    "Do NOT give anything extra.\n",
    "Strictly search in the document.\n",
    "\n",
    "STRICTLY extract all control IDs using the regex ONLY.\n",
    "\n",
    "Do NOT invent or skip any ID.\n",
    "\n",
    "STRICTLY extract all control IDs using this regex:\n",
    "{REGEX!r}\n",
    "\n",
    "Treat ALL numeric headings (0.1,0.2,0.3,0.4,1.1,1.2,2.3,1.1.2,A.1.2,A.2 etc.) as controls.\n",
    "Do NOT treat them as TOC headings.\n",
    "\n",
    "EXTRACT ONLY if all three are present in this sequence- ID, NAME and DESCRIPTION otherwise return null.\n",
    "\n",
    "DESCRIPTION CAN BE OF 5 TO 1500 characters.\n",
    "\n",
    "Consider all the controls given till the end.\n",
    "\n",
    "Use JSON list ONLY:\n",
    "\n",
    "[\n",
    "  {{\n",
    "    \"Control_id\": \"\",\n",
    "    \"Control_name\": \"\",\n",
    "    \"Control_type\":\"\",\n",
    "    \"Control_description\": \"\"\n",
    "  }}\n",
    "]\n",
    "\n",
    "TEXT:\n",
    "{chunks}\n",
    "\n",
    "Return ONLY JSON. No markdown. No text outside JSON.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"extracting controls\")\n",
    "    status_msg[uuid_of_file] = \"extracting controls from pdf\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    status_msg[uuid_of_file] = \"extraction complete\"\n",
    " \n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        print(\"⚠ JSON error\")\n",
    "        return []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0bc09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "225f558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client_df = pd.DataFrame(pd.read_json('test_2_user.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7f1cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_df = pd.DataFrame(pd.read_json('test_1_expert.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28719e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Control_id</th>\n",
       "      <th>Control_name</th>\n",
       "      <th>Control_type</th>\n",
       "      <th>Control_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PO.1</td>\n",
       "      <td>Define Security Requirements for Software Deve...</td>\n",
       "      <td></td>\n",
       "      <td>Ensure that security requirements for software...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PO.1.1</td>\n",
       "      <td>Identify and document all security requirements</td>\n",
       "      <td></td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PO.1.2</td>\n",
       "      <td>Identify and document security requirements fo...</td>\n",
       "      <td></td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PO.1.3</td>\n",
       "      <td>Communicate requirements to third parties</td>\n",
       "      <td></td>\n",
       "      <td>Communicate requirements to all third parties ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PO.2</td>\n",
       "      <td>Implement Roles and Responsibilities</td>\n",
       "      <td></td>\n",
       "      <td>Ensure that everyone inside and outside of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Control_id                                       Control_name Control_type  \\\n",
       "0       PO.1  Define Security Requirements for Software Deve...                \n",
       "1     PO.1.1    Identify and document all security requirements                \n",
       "2     PO.1.2  Identify and document security requirements fo...                \n",
       "3     PO.1.3          Communicate requirements to third parties                \n",
       "4       PO.2               Implement Roles and Responsibilities                \n",
       "\n",
       "                                 Control_description  \n",
       "0  Ensure that security requirements for software...  \n",
       "1  Identify and document all security requirement...  \n",
       "2  Identify and document all security requirement...  \n",
       "3  Communicate requirements to all third parties ...  \n",
       "4  Ensure that everyone inside and outside of the...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "081a44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comparision_dict(user_filename, expert_filename):\n",
    "    client_df = pd.DataFrame(pd.read_json(user_filename))\n",
    "    expert_df = pd.DataFrame(pd.read_json(expert_filename))\n",
    "    results = []\n",
    "    for client_idx ,client_row in client_df.iterrows():\n",
    "        c_name = client_row[\"Control_name\"]\n",
    "        c_desc = client_row[\"Control_description\"]\n",
    "        c_id = client_row['Control_id']\n",
    "        best_score = -1\n",
    "        best_match = None\n",
    "\n",
    "        for row_idx, row in expert_df[['Control_id','Control_name', 'Control_description','Deployment_points']].iterrows():\n",
    "            \n",
    "            f_id   = row.get(\"Control_id\", \"\")\n",
    "            f_name = row.get(\"Control_name\", \"\")\n",
    "            f_desc = row.get(\"Control_description\", \"\")\n",
    "\n",
    "            deployment_pts =row.get(\"Deployment_points\", \"\")\n",
    "            framework_text = f\"{f_name} {f_desc} {deployment_pts}\"\n",
    "            client_text    = f\"{c_name} {c_desc}\"\n",
    "\n",
    "            score = semantic_similarity(client_text, framework_text)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = row\n",
    "\n",
    "        \n",
    "        results.append({\n",
    "            \"User_Document_Control_Name\": c_name,\n",
    "            \"User_Document_Control_Description\": c_desc,\n",
    "            \"User_Document_Control_Id\":c_id,\n",
    "            \"Expert_Framework_Control_Id\": best_match.get(\"Control_id\", \"\"),\n",
    "            \"Expert_Framework_Control_Name\": best_match.get(\"Control_name\", \"\"),\n",
    "            \"Expert_Framework_Control_Description\": best_match.get(\"Control_description\", \"\"),\n",
    "            \"Deployment_Points\": best_match.get(\"Deployment_points\", []),\n",
    "            \"Comparison_Score\": best_score,\n",
    "            \n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d979954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Document_Control_Name</th>\n",
       "      <th>User_Document_Control_Description</th>\n",
       "      <th>User_Document_Control_Id</th>\n",
       "      <th>Expert_Framework_Control_Id</th>\n",
       "      <th>Expert_Framework_Control_Name</th>\n",
       "      <th>Expert_Framework_Control_Description</th>\n",
       "      <th>Deployment_Points</th>\n",
       "      <th>Comparison_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Define Security Requirements for Software Deve...</td>\n",
       "      <td>Ensure that security requirements for software...</td>\n",
       "      <td>PO.1</td>\n",
       "      <td>PO.1</td>\n",
       "      <td>Define Security Requirements for Software Deve...</td>\n",
       "      <td>Ensure that security requirements for software...</td>\n",
       "      <td>1. Establish a centralized repository for secu...</td>\n",
       "      <td>0.9073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Identify and document all security requirements</td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "      <td>PO.1.1</td>\n",
       "      <td>PO.1.2</td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "      <td>1. Define a set of risk-based security require...</td>\n",
       "      <td>0.8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Identify and document security requirements fo...</td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "      <td>PO.1.2</td>\n",
       "      <td>PO.1.2</td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "      <td>Identify and document all security requirement...</td>\n",
       "      <td>1. Define a set of risk-based security require...</td>\n",
       "      <td>0.8231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Communicate requirements to third parties</td>\n",
       "      <td>Communicate requirements to all third parties ...</td>\n",
       "      <td>PO.1.3</td>\n",
       "      <td>PO.1.3</td>\n",
       "      <td>Communicate requirements to all third parties</td>\n",
       "      <td>Communicate requirements to all third parties ...</td>\n",
       "      <td>1. Develop a core set of security requirements...</td>\n",
       "      <td>0.8437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Implement Roles and Responsibilities</td>\n",
       "      <td>Ensure that everyone inside and outside of the...</td>\n",
       "      <td>PO.2</td>\n",
       "      <td>PO.2</td>\n",
       "      <td>Implement Roles and Responsibilities</td>\n",
       "      <td>Ensure that everyone inside and outside of the...</td>\n",
       "      <td>1. Define clear roles and responsibilities for...</td>\n",
       "      <td>0.9197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Create new roles and alter responsibilities</td>\n",
       "      <td>Create new roles and alter responsibilities fo...</td>\n",
       "      <td>PO.2.1</td>\n",
       "      <td>PO.2.1</td>\n",
       "      <td>Create new roles and alter responsibilities fo...</td>\n",
       "      <td>Create new roles and alter responsibilities fo...</td>\n",
       "      <td>1. Assess the current roles and responsibiliti...</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Provide role-based training</td>\n",
       "      <td>Provide role-based training for all personnel ...</td>\n",
       "      <td>PO.2.2</td>\n",
       "      <td>PO.2.2</td>\n",
       "      <td>Provide role-based training for all personnel</td>\n",
       "      <td>Provide role-based training for all personnel ...</td>\n",
       "      <td>1. Identify the specific training needs for ea...</td>\n",
       "      <td>0.8520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          User_Document_Control_Name  \\\n",
       "0  Define Security Requirements for Software Deve...   \n",
       "1    Identify and document all security requirements   \n",
       "2  Identify and document security requirements fo...   \n",
       "3          Communicate requirements to third parties   \n",
       "4               Implement Roles and Responsibilities   \n",
       "5        Create new roles and alter responsibilities   \n",
       "6                        Provide role-based training   \n",
       "\n",
       "                   User_Document_Control_Description User_Document_Control_Id  \\\n",
       "0  Ensure that security requirements for software...                     PO.1   \n",
       "1  Identify and document all security requirement...                   PO.1.1   \n",
       "2  Identify and document all security requirement...                   PO.1.2   \n",
       "3  Communicate requirements to all third parties ...                   PO.1.3   \n",
       "4  Ensure that everyone inside and outside of the...                     PO.2   \n",
       "5  Create new roles and alter responsibilities fo...                   PO.2.1   \n",
       "6  Provide role-based training for all personnel ...                   PO.2.2   \n",
       "\n",
       "  Expert_Framework_Control_Id  \\\n",
       "0                        PO.1   \n",
       "1                      PO.1.2   \n",
       "2                      PO.1.2   \n",
       "3                      PO.1.3   \n",
       "4                        PO.2   \n",
       "5                      PO.2.1   \n",
       "6                      PO.2.2   \n",
       "\n",
       "                       Expert_Framework_Control_Name  \\\n",
       "0  Define Security Requirements for Software Deve...   \n",
       "1  Identify and document all security requirement...   \n",
       "2  Identify and document all security requirement...   \n",
       "3      Communicate requirements to all third parties   \n",
       "4               Implement Roles and Responsibilities   \n",
       "5  Create new roles and alter responsibilities fo...   \n",
       "6      Provide role-based training for all personnel   \n",
       "\n",
       "                Expert_Framework_Control_Description  \\\n",
       "0  Ensure that security requirements for software...   \n",
       "1  Identify and document all security requirement...   \n",
       "2  Identify and document all security requirement...   \n",
       "3  Communicate requirements to all third parties ...   \n",
       "4  Ensure that everyone inside and outside of the...   \n",
       "5  Create new roles and alter responsibilities fo...   \n",
       "6  Provide role-based training for all personnel ...   \n",
       "\n",
       "                                   Deployment_Points  Comparison_Score  \n",
       "0  1. Establish a centralized repository for secu...            0.9073  \n",
       "1  1. Define a set of risk-based security require...            0.8459  \n",
       "2  1. Define a set of risk-based security require...            0.8231  \n",
       "3  1. Develop a core set of security requirements...            0.8437  \n",
       "4  1. Define clear roles and responsibilities for...            0.9197  \n",
       "5  1. Assess the current roles and responsibiliti...            0.9274  \n",
       "6  1. Identify the specific training needs for ea...            0.8520  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(get_comparision_dict('test_2_user.json','test_1_expert.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f8ee50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
